{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE LOS ARCHIVOS CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "common_player_info = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\common_player_info.csv')\n",
    "draft_combine_stats = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\draft_combine_stats.csv')\n",
    "draft_history = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\draft_history.csv')\n",
    "game = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\game.csv')\n",
    "game_info = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\game_info.csv')\n",
    "game_summary = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\game_summary.csv')\n",
    "inactive_players = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\inactive_players.csv')\n",
    "line_score = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\line_score.csv')\n",
    "officials = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\officials.csv')\n",
    "other_stats = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\other_stats.csv')\n",
    "player = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\player.csv')\n",
    "play_by_play = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\play_by_play.csv')\n",
    "team = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\team.csv')\n",
    "team_details = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\team_details.csv')\n",
    "team_history = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\team_history.csv')\n",
    "team_info_common = pd.read_csv(r'C:\\Users\\matis\\OneDrive\\Documentos\\NBA dataset\\csv\\team_info_common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al cargar datos en common_player_info: ('23000', \"[23000] [Microsoft][ODBC SQL Server Driver][SQL Server]Violation of PRIMARY KEY constraint 'PK__common_p__543848DF81C069FE'. Cannot insert duplicate key in object 'dbo.common_player_info'. The duplicate key value is (76001). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC SQL Server Driver][SQL Server]The statement has been terminated. (3621)\")\n",
      "Datos cargados en draft_combine_stats correctamente.\n",
      "Datos cargados en draft_history correctamente.\n",
      "Datos cargados en officials correctamente.\n",
      "Datos cargados en player correctamente.\n",
      "Datos cargados en inactive_players correctamente.\n",
      "Error al cargar datos en game: ('42S22', \"[42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'blk_home'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "Error al cargar datos en game_info: ('22018', '[22018] [Microsoft][ODBC SQL Server Driver][SQL Server]Operand type clash: int is incompatible with time (206) (SQLExecDirectW); [22018] [Microsoft][ODBC SQL Server Driver][SQL Server]Statement(s) could not be prepared. (8180)')\n",
      "Error al cargar datos en game_summary: ('42S22', \"[42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'live_pc_time'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "Error al cargar datos en line_score: ('42S22', \"[42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_qtr4_home'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot1_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot2_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot3_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot4_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot5_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot6_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot7_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot8_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot9_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot10_home'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot1_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot2_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot3_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot4_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot5_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot6_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot7_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot8_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot9_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid column name 'pts_ot10_away'. (207); [42S22] [Microsoft][ODBC SQL Server Driver][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "Datos cargados en other_stats correctamente.\n",
      "Datos cargados en team correctamente.\n",
      "Datos cargados en team_details correctamente.\n",
      "Datos cargados en team_history correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# Configurar la conexión a SQL Server (autenticación de Windows)\n",
    "server = r'Asus_Mati\\SQLEXPRESS'\n",
    "database = 'DAFT10_PF'\n",
    "conn = pyodbc.connect(f'DRIVER=SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes')\n",
    "\n",
    "# Función para limpiar y preparar los datos\n",
    "def limpiar_datos(df):\n",
    "    # Reemplazar valores no válidos y ajustar precisión\n",
    "    for col in df.select_dtypes(include=['float']):\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').round(2)  # Ajustar decimales\n",
    "    df.fillna(value=0, inplace=True)  # Reemplazar NaN con 0 (o un valor adecuado)\n",
    "    return df\n",
    "\n",
    "# Función para cargar datos a SQL Server\n",
    "def cargar_datos(csv_file, table_name, conn):\n",
    "    try:\n",
    "        # Cargar el CSV en un DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = limpiar_datos(df)\n",
    "\n",
    "        # Preparar SQL para inserción en bloque\n",
    "        columns = ', '.join(df.columns)\n",
    "        placeholders = ', '.join(['?' for _ in df.columns])\n",
    "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Inserción en bloque\n",
    "        data = [tuple(row) for row in df.to_numpy()]\n",
    "        cursor = conn.cursor()\n",
    "        cursor.executemany(sql, data)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        print(f\"Datos cargados en {table_name} correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar datos en {table_name}: {e}\")\n",
    "\n",
    "# Cargar cada archivo CSV en su tabla correspondiente\n",
    "archivos = {\n",
    "    \"common_player_info.csv\": \"common_player_info\",\n",
    "    \"draft_combine_stats.csv\": \"draft_combine_stats\",\n",
    "    \"draft_history.csv\": \"draft_history\",\n",
    "    \"officials.csv\": \"officials\",\n",
    "    \"player.csv\": \"player\",\n",
    "    \"inactive_players.csv\": \"inactive_players\",\n",
    "    \"game.csv\": \"game\",\n",
    "    \"game_info.csv\": \"game_info\",\n",
    "    \"game_summary.csv\": \"game_summary\",\n",
    "    \"line_score.csv\": \"line_score\",\n",
    "    \"other_stats.csv\": \"other_stats\",\n",
    "    \"team.csv\": \"team\",\n",
    "    \"team_details.csv\": \"team_details\",\n",
    "    \"team_history.csv\": \"team_history\"\n",
    "}\n",
    "\n",
    "# Iterar sobre los archivos y cargar los datos\n",
    "for archivo, tabla in archivos.items():\n",
    "    cargar_datos(archivo, tabla, conn)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "realice la transformacion de datos para que se cargaran correctamente a la base de SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en common_player_info correctamente.\n",
      "Datos cargados en draft_combine_stats correctamente.\n",
      "Datos cargados en draft_history correctamente.\n",
      "Datos cargados en officials correctamente.\n",
      "Datos cargados en player correctamente.\n",
      "Datos cargados en inactive_players correctamente.\n",
      "Datos cargados en game correctamente.\n",
      "Datos cargados en game_info correctamente.\n",
      "Datos cargados en game_summary correctamente.\n",
      "Datos cargados en line_score correctamente.\n",
      "Datos cargados en other_stats correctamente.\n",
      "Datos cargados en team correctamente.\n",
      "Datos cargados en team_details correctamente.\n",
      "Datos cargados en team_history correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# Configurar la conexión a SQL Server\n",
    "server = r'Asus_Mati\\SQLEXPRESS'\n",
    "database = 'DAFT10_PF'\n",
    "conn = pyodbc.connect(f'DRIVER=SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes')\n",
    "#server: Especifica el nombre del servidor SQL Server.\n",
    "#database: Define el nombre de la base de datos.\n",
    "#conn: Establece una conexión a SQL Server utilizando pyodbc con autenticación integrada de Windows.\n",
    "\n",
    "\n",
    "def obtener_columnas_tabla(conn, table_name):\n",
    "    query = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    return [row[0] for row in cursor.fetchall()]\n",
    "# Consulta las columnas de la tabla especificada en la base de datos mediante la vista INFORMATION_SCHEMA.COLUMNS.\n",
    "# Retorna una lista de nombres de columnas, que será utilizada para filtrar los datos del archivo CSV.\n",
    "\n",
    "\n",
    "def limpiar_y_preparar_datos(df, columnas_tabla):\n",
    "    df = df.drop_duplicates()  # Eliminar duplicados\n",
    "    df = df[columnas_tabla]  # Filtrar solo columnas válidas\n",
    "    df.fillna(value=0, inplace=True)  # Manejar valores nulos\n",
    "    return df\n",
    "#drop_duplicates(): Elimina filas duplicadas del DataFrame.\n",
    "#df[columnas_tabla]: Selecciona solo las columnas que coinciden con las de la tabla en la base de datos, evitando errores.\n",
    "#fillna(value=0): Reemplaza valores nulos con 0 para evitar conflictos al insertar datos.\n",
    "\n",
    "def cargar_datos(csv_file, table_name, conn):\n",
    "    try:\n",
    "        # Cargar el archivo CSV\n",
    "        df = pd.read_csv(csv_file)\n",
    "        columnas_tabla = obtener_columnas_tabla(conn, table_name)\n",
    "        df = limpiar_y_preparar_datos(df, columnas_tabla)\n",
    "\n",
    "        # Preparar la consulta SQL\n",
    "        columns = ', '.join(df.columns)\n",
    "        placeholders = ', '.join(['?' for _ in df.columns])\n",
    "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Ejecutar inserción\n",
    "        data = [tuple(row) for row in df.to_numpy()]\n",
    "        cursor = conn.cursor()\n",
    "        cursor.executemany(sql, data)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        print(f\"Datos cargados en {table_name} correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar datos en {table_name}: {e}\")\n",
    "\n",
    "# Carga el archivo CSV en un DataFrame de pandas.\n",
    "# Filtra las columnas del CSV según las columnas de la tabla SQL.\n",
    "# Crea una instrucción INSERT INTO dinámica usando los nombres de las columnas y placeholders (?) para los valores.\n",
    "# Convierte los datos del DataFrame en una lista de tuplas para usar con executemany.\n",
    "#Inserta los datos en la tabla SQL y confirma los cambios.\n",
    "\n",
    "# Diccionario de archivos y tablas\n",
    "archivos = {\n",
    "    \"common_player_info.csv\": \"common_player_info\",\n",
    "    \"draft_combine_stats.csv\": \"draft_combine_stats\",\n",
    "    \"draft_history.csv\": \"draft_history\",\n",
    "    \"officials.csv\": \"officials\",\n",
    "    \"player.csv\": \"player\",\n",
    "    \"inactive_players.csv\": \"inactive_players\",\n",
    "    \"game.csv\": \"game\",\n",
    "    \"game_info.csv\": \"game_info\",\n",
    "    \"game_summary.csv\": \"game_summary\",\n",
    "    \"line_score.csv\": \"line_score\",\n",
    "    \"other_stats.csv\": \"other_stats\",\n",
    "    \"team.csv\": \"team\",\n",
    "    \"team_details.csv\": \"team_details\",\n",
    "    \"team_history.csv\": \"team_history\"\n",
    "}\n",
    "#Mapea cada archivo CSV con la tabla correspondiente en la base de datos.\n",
    "\n",
    "for archivo, tabla in archivos.items():\n",
    "    cargar_datos(archivo, tabla, conn)\n",
    "#Itera sobre el diccionario, llamando a la función cargar_datos para cada archivo y tabla.\n",
    "conn.close()\n",
    "#Cierra la conexión a la base de datos después de completar la carga de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen<br>\n",
    "El script automatiza el proceso de:<br>\n",
    "<br>\n",
    "Leer múltiples archivos CSV.<br>\n",
    "Limpiar y preparar los datos.<br>\n",
    "Insertarlos en las tablas correspondientes en SQL Server, gestionando posibles errores.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
